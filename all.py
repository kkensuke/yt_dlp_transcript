import os
import sys
import json
import argparse
import re
from datetime import timedelta
import yt_dlp
from urllib.parse import urlparse, parse_qs

# ===== CONFIGURATION =====
# Add your Gemini API key here
GEMINI_API_KEY = os.getenv("GEMINI_API_KEY")
# GEMINI_API_KEY = "YOUR_GEMINI_API_KEY"

MAX_SUMMARY_LENGTH = 50000  # Max characters for summary input
# =========================


def extract_video_id(url):
    """
    Extracts the YouTube video ID from a variety of URL formats.
    Handles standard, shortened, embed, shorts, live, and music URLs,
    as well as regional domains and mobile versions.
    """
    if not url:
        return None

    # Handle the case where the input is just the 11-character video ID
    if re.match(r'^[a-zA-Z0-9_-]{11}$', url):
        return url

    # Prepend 'http://' if no scheme is present to help urlparse
    if not re.match(r'http(s)?://', url):
        url = 'http://' + url

    parsed_url = urlparse(url)
    hostname = parsed_url.hostname

    # A regex to match youtube.com, youtu.be, and regional/mobile variations
    # e.g., www.youtube.com, m.youtube.co.uk, music.youtube.com, youtu.be
    if not hostname or not re.match(r'(?:www\.|m\.|music\.)?youtube\.co(m|\.uk|\.jp|\.de|.\w{2})|youtu\.be', hostname):
        return None

    # Case 1: Standard /watch url (e.g., youtube.com/watch?v=VIDEO_ID)
    if parsed_url.path == '/watch':
        query_params = parse_qs(parsed_url.query)
        return query_params.get('v', [None])[0]

    # Case 2: Shortened URL (e.g., youtu.be/VIDEO_ID)
    if hostname == 'youtu.be':
        # The ID is the first part of the path, ignore query params
        return parsed_url.path.split('/')[1].split('?')[0]

    # Case 3: Embed, Shorts, Live, or old /v/ urls
    # (e.g., /embed/VIDEO_ID, /shorts/VIDEO_ID, /live/VIDEO_ID, /v/VIDEO_ID)
    path_parts = parsed_url.path.split('/')
    if len(path_parts) > 2 and path_parts[1] in ['embed', 'shorts', 'live', 'v']:
        # The ID is the second part of the path, ignore query params
        return path_parts[2].split('?')[0]

    return None

def format_timestamp(seconds):
    """Convert seconds to HH:MM:SS format."""
    return str(timedelta(seconds=int(seconds)))


def detect_video_language(title, description=""):
    """Simple language detection based on title and description."""
    text = (title + " " + description).lower()
    
    # Japanese detection - look for hiragana, katakana, or common Japanese words
    japanese_indicators = ['„Çí', '„ÅØ', '„Åå', '„Å´', '„Åß', '„Å®', '„ÅÆ', '„Åß„Åô', '„Åæ„Åô', '„Åó„Åü', '„Åô„Çã', '„ÅÇ„Çã', '„ÅÑ„Çã']
    if any(indicator in text for indicator in japanese_indicators):
        return 'ja'
    
    # Could add more language detection here
    return 'en'  # Default to English


def get_video_info_and_transcript(video_id):
    """Get video info and transcript using yt-dlp."""
    
    ydl_opts = {
        'writesubtitles': True,
        'writeautomaticsub': True,
        'skip_download': True,
        'quiet': True,
        'no_warnings': True,
        'cookiesfrombrowser': ('chrome',),
    }
    
    try:
        with yt_dlp.YoutubeDL(ydl_opts) as ydl:
            print("Extracting video information...")
            info = ydl.extract_info(video_id, download=False)
            
            title = info.get('title', 'Unknown Title')
            video_id = info.get('id', 'Unknown ID')
            duration = info.get('duration', 0)
            description = info.get('description', '')
            
            print(f"Title: {title}")
            print(f"Video ID: {video_id}")
            print(f"Duration: {format_timestamp(duration)}")
            
            # Detect video language
            detected_language = detect_video_language(title, description)
            print(f"Detected language: {detected_language}")
            
            # Look for subtitles
            subtitles = info.get('subtitles', {})
            automatic_captions = info.get('automatic_captions', {})
            
            print(f"\nAvailable manual subtitles: {list(subtitles.keys())}")
            print(f"Available auto captions (first 10): {list(automatic_captions.keys())[:10]}...")
            
            # Choose language based on detection
            if detected_language == 'ja':
                preferred_languages = ['ja', 'ja-JP', 'en', 'en-US', 'en-GB']
            else:
                preferred_languages = ['en', 'en-US', 'en-GB', 'ja', 'ja-JP']
            
            transcript_data = None
            transcript_type = None
            
            # Try manual subtitles first
            for lang_code in preferred_languages:
                if lang_code in subtitles:
                    transcript_data = subtitles[lang_code]
                    transcript_type = f"Manual ({lang_code})"
                    break
            
            # Then try automatic captions
            if not transcript_data:
                for lang_code in preferred_languages:
                    if lang_code in automatic_captions:
                        transcript_data = automatic_captions[lang_code]
                        transcript_type = f"Auto-generated ({lang_code})"
                        break
            
            # If still no match, try any available language
            if not transcript_data:
                if subtitles:
                    lang_code = list(subtitles.keys())[0]
                    transcript_data = subtitles[lang_code]
                    transcript_type = f"Manual ({lang_code})"
                elif automatic_captions:
                    lang_code = list(automatic_captions.keys())[0]
                    transcript_data = automatic_captions[lang_code]
                    transcript_type = f"Auto-generated ({lang_code})"
            
            if transcript_data:
                print(f"Using transcript: {transcript_type}")
                return info, transcript_data
            else:
                print("No transcripts found")
                return info, None
                
    except Exception as e:
        print(f"Error extracting video info: {str(e)}")
        return None, None


def download_and_parse_transcript(transcript_data):
    """Download and parse the transcript file."""
    import urllib.request
    import urllib.error
    
    # Find the best format (prefer json, then vtt, then srt)
    best_format = None
    for item in transcript_data:
        ext = item.get('ext', '')
        if ext == 'json3':
            best_format = item
            break
        elif ext == 'vtt' and not best_format:
            best_format = item
        elif ext == 'srv1' and not best_format:
            best_format = item
    
    if not best_format:
        print("No suitable transcript format found")
        return None
    
    print(f"Downloading transcript in {best_format.get('ext')} format...")
    
    try:
        # Directly fetch the transcript URL
        transcript_url = best_format['url']
        print(f"Fetching from: {transcript_url}")
        
        # Download only the transcript file (small file)
        with urllib.request.urlopen(transcript_url) as response:
            content = response.read().decode('utf-8')
        
        print(f"Downloaded transcript ({len(content)} characters)")
        
        # Parse based on format
        if best_format.get('ext') == 'json3':
            return parse_json3_transcript(content)
        elif best_format.get('ext') == 'vtt':
            return parse_vtt_transcript(content)
        else:
            return parse_srv1_transcript(content)
                    
    except Exception as e:
        print(f"Error downloading transcript: {str(e)}")
        return None


def parse_json3_transcript(content):
    """Parse JSON3 format transcript."""
    try:
        data = json.loads(content)
        transcript = []
        
        events = data.get('events', [])
        for event in events:
            if 'segs' in event:
                start_time = event.get('tStartMs', 0) / 1000.0
                text_parts = []
                for seg in event['segs']:
                    if 'utf8' in seg:
                        text_parts.append(seg['utf8'])
                
                text = ''.join(text_parts).strip()
                if text:
                    transcript.append({
                        'text': text,
                        'start': start_time,
                        'duration': event.get('dDurationMs', 0) / 1000.0
                    })
        
        return transcript
    except Exception as e:
        print(f"Error parsing JSON3 transcript: {str(e)}")
        return None


def parse_vtt_transcript(content):
    """Parse VTT format transcript."""
    try:
        transcript = []
        lines = content.split('\n')
        
        i = 0
        while i < len(lines):
            line = lines[i].strip()
            
            # Look for timestamp lines
            if '-->' in line:
                time_parts = line.split(' --> ')
                start_time = vtt_time_to_seconds(time_parts[0])
                
                # Get the text (next non-empty lines)
                i += 1
                text_parts = []
                while i < len(lines) and lines[i].strip():
                    text_parts.append(lines[i].strip())
                    i += 1
                
                text = ' '.join(text_parts)
                # Remove VTT tags
                text = re.sub(r'<[^>]+>', '', text)
                
                if text:
                    transcript.append({
                        'text': text,
                        'start': start_time,
                        'duration': 0  # VTT doesn't always have duration
                    })
            
            i += 1
        
        return transcript
    except Exception as e:
        print(f"Error parsing VTT transcript: {str(e)}")
        return None


def parse_srv1_transcript(content):
    """Parse SRV1 (XML) format transcript."""
    try:
        import xml.etree.ElementTree as ET
        
        root = ET.fromstring(content)
        transcript = []
        
        for text_elem in root.findall('.//text'):
            start_time = float(text_elem.get('start', 0))
            duration = float(text_elem.get('dur', 0))
            text = text_elem.text or ''
            text = text.strip()
            
            if text:
                transcript.append({
                    'text': text,
                    'start': start_time,
                    'duration': duration
                })
        
        return transcript
    except Exception as e:
        print(f"Error parsing SRV1 transcript: {str(e)}")
        return None


def vtt_time_to_seconds(time_str):
    """Convert VTT timestamp to seconds."""
    try:
        # Remove milliseconds part if present
        time_str = time_str.split('.')[0]
        parts = time_str.split(':')
        
        if len(parts) == 3:
            hours, minutes, seconds = map(int, parts)
            return hours * 3600 + minutes * 60 + seconds
        elif len(parts) == 2:
            minutes, seconds = map(int, parts)
            return minutes * 60 + seconds
        else:
            return int(parts[0])
    except:
        return 0


def clean_japanese_text(text):
    """Clean Japanese transcript text by removing music tags and unnecessary spaces."""
    import re
    
    # Remove common Japanese music/sound tags
    music_tags = ['[Èü≥Ê•Ω]', '‚ô™', '‚ô´', '‚ô¨', '‚ô©', '[ÊãçÊâã]', '[Á¨ë„ÅÑ]', '[Á¨ë]', '[Èü≥ÈüøÂäπÊûú]', '[ÂäπÊûúÈü≥]']
    for tag in music_tags:
        text = text.replace(tag, '')
    
    # Remove spaces between Japanese characters
    # This regex matches spaces that are between Japanese characters (hiragana, katakana, kanji)
    # Unicode ranges: Hiragana (3040-309F), Katakana (30A0-30FF), CJK Unified Ideographs (4E00-9FAF)
    japanese_char_pattern = r'[\u3040-\u309F\u30A0-\u30FF\u4E00-\u9FAF]'
    
    # Remove spaces between Japanese characters
    text = re.sub(f'({japanese_char_pattern})\\s+({japanese_char_pattern})', r'\1\2', text)
    
    # Clean up multiple spaces
    text = re.sub(r'\s+', ' ', text)
    
    # Remove leading/trailing spaces
    text = text.strip()
    
    return text


def transcript_to_markdown(transcript, video_info, include_timestamps=True):
    """Convert transcript to markdown format."""
    title = video_info.get('title', 'Unknown Title')
    video_id = video_info.get('id', 'Unknown ID')
    
    # Detect if this is Japanese content
    is_japanese = detect_video_language(title) == 'ja'
    
    markdown = f"# {title}\n\n"
    markdown += f"**Video ID:** {video_id}  \n"
    markdown += f"**YouTube URL:** https://www.youtube.com/watch?v={video_id}\n\n"
    markdown += "---\n\n"
    
    if not transcript:
        markdown += "*No transcript available for this video.*\n"
        return markdown
    
    # Group transcript entries into paragraphs
    current_paragraph = ""
    current_start_time = None
    
    for entry in transcript:
        text = entry['text'].strip()
        
        if not text:
            continue
        
        # Clean Japanese text if needed
        if is_japanese:
            text = clean_japanese_text(text)
            if not text:  # Skip if text becomes empty after cleaning
                continue
            
        if current_start_time is None:
            current_start_time = entry['start']
        
        current_paragraph += text + " "
        
        # Start new paragraph if text ends with sentence punctuation
        if text.endswith(('.', '!', '?', '„ÄÇ', 'ÔºÅ', 'Ôºü')) or len(current_paragraph) > 500:
            if include_timestamps:
                timestamp = format_timestamp(current_start_time)
                final_text = current_paragraph.strip()
                if is_japanese:
                    final_text = clean_japanese_text(final_text)
                markdown += f"**[{timestamp}]** {final_text}\n\n"
            else:
                final_text = current_paragraph.strip()
                if is_japanese:
                    final_text = clean_japanese_text(final_text)
                markdown += f"{final_text}\n\n"
            
            current_paragraph = ""
            current_start_time = None
    
    # Add any remaining text
    if current_paragraph.strip():
        final_text = current_paragraph.strip()
        if is_japanese:
            final_text = clean_japanese_text(final_text)
        
        if final_text:  # Only add if text remains after cleaning
            if include_timestamps and current_start_time is not None:
                timestamp = format_timestamp(current_start_time)
                markdown += f"**[{timestamp}]** {final_text}\n\n"
            else:
                markdown += f"{final_text}\n\n"
    
    return markdown


def call_gemini_api(text, api_key, language='auto'):
    """Call Gemini API to summarize the transcript."""
    import json
    import urllib.request
    import urllib.error
    
    url = f"https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?key={api_key}"
    
    # Detect language if auto
    if language == 'auto':
        # Simple detection based on Japanese characters
        japanese_chars = sum(1 for char in text if '\u3040' <= char <= '\u309F' or '\u30A0' <= char <= '\u30FF' or '\u4E00' <= char <= '\u9FAF')
        total_chars = len([char for char in text if char.isalpha() or '\u3040' <= char <= '\u9FAF'])
        
        if total_chars > 0 and japanese_chars / total_chars > 0.3:  # If >30% Japanese characters
            language = 'ja'
        else:
            language = 'en'
    
    # Prepare language-specific prompts
    if language == 'ja':
        # PROMPT FOR JAPANESE
        prompt = f"""
        „ÅÇ„Å™„Åü„ÅØÁÜüÁ∑¥„Åó„Åü„ÉÜ„ÇØ„Éã„Ç´„É´„É©„Ç§„Çø„ÉºÂÖº„Ç¢„Éä„É™„Çπ„Éà„Åß„Åô„ÄÇ„ÅÇ„Å™„Åü„ÅÆ„Çø„Çπ„ÇØ„ÅØ„ÄÅÊèê‰æõ„Åï„Çå„ÅüÂãïÁîª„ÅÆÊñáÂ≠óËµ∑„Åì„Åó„Çí„ÄÅË™≠„Åø„ÇÑ„Åô„ÅèÊßãÈÄ†Âåñ„Åï„Çå„ÄÅ„Åã„Å§Â≠¶Ë°ìÁöÑ„Å´Ê≠£Á¢∫„Å™„Éû„Éº„ÇØ„ÉÄ„Ç¶„É≥ÂΩ¢Âºè„ÅÆË¶ÅÁ¥Ñ„Éâ„Ç≠„É•„É°„É≥„Éà„Å´Â§âÊèõ„Åô„Çã„Åì„Å®„Åß„Åô„ÄÇ„ÄÇ
        
        „ÄêÂâçÂá¶ÁêÜ„É´„Éº„É´„Äë
        - ÊñáÂ≠óËµ∑„Åì„Åó„Å´ÂêåÈü≥Áï∞Áæ©Ë™û„Å™„Å©„ÅÆË™§Â≠ó„ÉªASRË™§Ë™çË≠ò„Åå„ÅÇ„Çå„Å∞ÊñáËÑà„Åß‰øÆÊ≠£„ÉªÂâäÈô§„Åó„Å¶Ëá™ÁÑ∂„Å™Êó•Êú¨Ë™û„Å´„Åó„Å¶„Åè„Å†„Åï„ÅÑ„ÄÇ„Åü„Å†„Åó„ÄÅ**‰∏çÁ¢∫„Åã„Å™Ëß£ÈáàÁÆáÊâÄ„ÅØ[‰∏çÁ¢∫„Åã]„Çø„Ç∞**„Çí‰ªò„Åë„Å¶Á§∫„Åó„Å¶„Åè„Å†„Åï„ÅÑ„ÄÇ
        - Â∞ÇÈñÄÁî®Ë™û„ÅØÂéüË™ûÔºàËã±Ë™ûÔºâ„ÅåÂ≠òÂú®„Åô„ÇãÂ†¥Âêà„ÅØÂéüË™û„ÇíÊã¨Âºß„Åß‰ΩµË®ò„Åó„Å¶„Åè„Å†„Åï„ÅÑÔºà‰æãÔºöÁµåÈ®ìÁöÑ„É™„Çπ„ÇØÔºàempirical riskÔºâÔºâ„ÄÇ
        - Êï∞Âºè„Éª„Ç¢„É´„Ç¥„É™„Ç∫„É†„ÅØÂèØËÉΩ„Å™Èôê„ÇäLaTeXÂΩ¢Âºè„ÅßÁ§∫„Åó„Å¶„Åè„Å†„Åï„ÅÑÔºà`$$...$$`Ôºâ„ÄÇ
        
        **ÂøÖ„Åö‰ª•‰∏ã„ÅÆÊßãÊàê„Å®„Éû„Éº„ÇØ„ÉÄ„Ç¶„É≥ÊåáÂÆö„Å´Âé≥ÂØÜ„Å´Âæì„Å£„Å¶„ÄÅÂøúÁ≠îÂÖ®‰Ωì„Çí‰ΩúÊàê„Åó„Å¶„Åè„Å†„Åï„ÅÑÔºö**
        
        ## üìù Ë¶ÅÁ¥Ñ
        ÂãïÁîª„ÅÆ‰∏ªÈ°å„ÄÅÁõÆÁöÑ„ÄÅ„Åù„Åó„Å¶‰∏ªË¶Å„Å™Áô∫Ë¶ã„Å´„Å§„ÅÑ„Å¶„ÅÆÁ∞°ÊΩî„Å™1ÊÆµËêΩ„ÅÆÊ¶ÇË¶Å„ÄÇ
        
        ## üîë ‰∏ªË¶Å„Å™Ê¶ÇÂøµ„Å®„Ç≠„Éº„ÉØ„Éº„ÉâÔºàÂéüË™û„ÇÇÊã¨Âºß„ÅßÂä†„Åà„ÇãÔºâ
        - **Áî®Ë™ûA:** Á∞°ÊΩî„Å™Ë™¨Êòé„ÄÅÈáçË¶ÅÂ∫¶ÔºàÈ´ò/‰∏≠/‰ΩéÔºâ„ÄÇ
        - **Áî®Ë™ûB:** ...
        
        ## ‚ú® ÈáçË¶Å„Éù„Ç§„É≥„Éà (ÁÆáÊù°Êõ∏„Åç)
        ÂãïÁîª„Åã„ÇâÂæó„Çâ„Çå„ÇãÈáçË¶Å„Å™„Éù„Ç§„É≥„Éà„ÇÑÁô∫Ë¶ã„Çí„ÅÑ„Åè„Å§„Åã„É™„Çπ„Éà„Ç¢„ÉÉ„Éó„Åó„Å¶„Åè„Å†„Åï„ÅÑ„ÄÇÁ∞°ÊΩî„ÅßË™≠„Åø„ÇÑ„Åô„ÅÑÁÆáÊù°Êõ∏„Åç„Åß„ÄÅÂêÑÈ†ÖÁõÆ„ÅØÂÆåÂÖ®„Å™ÊñáÁ´†„Å´„Åó„Å¶„Åè„Å†„Åï„ÅÑ„ÄÇ
        
        ## üìÑ Ë©≥Á¥∞„Å™ÂàÜÊûê
        ÂãïÁîª„ÅßÊèêÁ§∫„Åï„Çå„Åü‰∏ªË¶Å„Å™„Ç¢„Ç§„Éá„Ç¢„ÇíË´ñÁêÜÁöÑ„ÉªÊßãÈÄ†ÁöÑ„Å´Áµê„Å≥„Å§„Åë„ÄÅ„ÄåËÉåÊôØ„Äç„Äå‰ªïÁµÑ„ÅøÔºàhowÔºâ„Äç„ÄåÁêÜÁî±ÔºàwhyÔºâ„Äç„ÄåÈñ¢ÈÄ£„Åô„Çã‰æã„Åæ„Åü„ÅØÁõ¥ÊÑüÁöÑ„Å™Ë™¨Êòé„Äç„ÇíÂàÜ„Åã„Çä„ÇÑ„Åô„ÅèÈ´òÊ†°Áîü„Å´„ÇÇ„Çè„Åã„Çã„Çà„ÅÜ„Å´Ëß£Ë™¨„Åó„Å¶„Åè„Å†„Åï„ÅÑ„ÄÇÂàÜÈáè„ÅØË™¨Êòé„ÅÆÈõ£ÊòìÂ∫¶„Å´Âøú„Åò„Å¶Ë™øÊï¥„Åó„Å¶„Åè„Å†„Åï„ÅÑ„ÄÇ
        - ÂøÖË¶Å„Å™„ÇâÁü≠„ÅÑÊì¨‰ºº„Ç≥„Éº„Éâ„ÄÅÂõ≥ÂºèÁöÑ„ÅÆË™¨Êòé„ÄÅ„Åæ„Åü„ÅØÊï∞ÂºèÔºàLaTeXÔºâ„ÇíÂÖ•„Çå„Å¶„Åè„Å†„Åï„ÅÑ„ÄÇ
        - Èï∑„Åè„Å™„ÇãÂ†¥Âêà„ÅØÂ∞èË¶ãÂá∫„ÅóÔºà###Ôºâ„ÅßÂå∫Âàá„Çã„ÄÇ
        
        ## üí¨ Ê≥®ÁõÆ„Åô„Åπ„ÅçÂºïÁî®
        ‰∏≠ÂøÉÁöÑ„Å™„Ç¢„Ç§„Éá„Ç¢„ÇíÊçâ„Åà„Å¶„ÅÑ„Çã„ÄÅÊúÄ„ÇÇÈáçË¶Å„Åæ„Åü„ÅØÂΩ±ÈüøÂäõ„ÅÆ„ÅÇ„ÇãÂºïÁî®„Çí2„Äú3ÂÄã„ÄÅÊñáÂ≠óËµ∑„Åì„Åó„Åã„ÇâÊäΩÂá∫„Åó„Å¶„Åè„Å†„Åï„ÅÑ„ÄÇ„Éû„Éº„ÇØ„ÉÄ„Ç¶„É≥„ÅÆÂºïÁî®Á¨¶Ôºà>Ôºâ„Çí‰ΩøÁî®„Åó„Å¶„Éï„Ç©„Éº„Éû„ÉÉ„Éà„Åó„Å¶„Åè„Å†„Åï„ÅÑ„ÄÇ
        > "ÂΩ±ÈüøÂäõ„ÅÆ„ÅÇ„ÇãÂºïÁî®1..."
        > "ÂΩ±ÈüøÂäõ„ÅÆ„ÅÇ„ÇãÂºïÁî®2..."
        
        ### üßê Critical EvaluationÔºàÊâπÂà§ÁöÑË©ï‰æ°Ôºâ
        ÂãïÁîª„ÅÆË≠∞Ë´ñ„Å´„Åä„Åë„Çã **‰∏çË∂≥ÁÇπ„ÄÅË¶ãËêΩ„Å®„Åï„Çå„ÅüË¶ñÁÇπ„ÄÅÂº±„ÅÑË´ñÁÇπ„ÄÅÊòé„Çâ„Åã„Å™Ë™§„Çä** „ÇíÊåáÊëò„Åó„Å¶„Åè„Å†„Åï„ÅÑ„ÄÇ„Åæ„Åü„ÄÅË™¨Êòé„ÇíÂº∑Âåñ„Åô„Çã„Åü„ÇÅ„Å´„Å©„ÅÆ„Çà„ÅÜ„Å™Ë¶ÅÁ¥†„ÅåÂê´„Åæ„Çå„Çã„Åπ„Åç„Å†„Å£„Åü„Åã„ÇíÊèêÊ°à„Åó„Å¶„Åè„Å†„Åï„ÅÑ„ÄÇ
        
        ## üöÄ ÂÆüÁî®ÁöÑ„Å™Â≠¶„Å≥„Å®ÁµêË´ñ
        ‰∏ªË¶Å„Å™Â≠¶„Å≥„ÅßÁ∑†„ÇÅ„Åè„Åè„Å£„Å¶„Åè„Å†„Åï„ÅÑ„ÄÇ„Åì„ÅÆÂãïÁîª„ÇíË¶ñËÅ¥„Åó„ÅüÂæå„ÄÅË¶ñËÅ¥ËÄÖ„ÅØ‰Ωï„Çí„Åô„Åπ„Åç„Åã„ÄÅ‰Ωï„ÇíË®òÊÜ∂„Åô„Åπ„Åç„Åã„ÄÅ„Åæ„Åü„ÅØ‰Ωï„ÇíËÄÉÊÖÆ„Åô„Åπ„Åç„Åã„ÄÇÁü≠„ÅÑÊÆµËêΩ„Åæ„Åü„ÅØÊúÄÂæå„ÅÆ„ÅÑ„Åè„Å§„Åã„ÅÆÁÆáÊù°Êõ∏„Åç„ÅßË®òËø∞„Åß„Åç„Åæ„Åô„ÄÇ
        
        ---
        Ë¶ÅÁ¥Ñ„Åô„ÇãÊñáÂ≠óËµ∑„Åì„Åó„ÅØ‰ª•‰∏ã„ÅÆÈÄö„Çä„Åß„ÅôÔºö
        {text}
        """
    else:  # Default to English
        # PROMPT FOR ENGLISH
        prompt = f"""
        You are a skilled technical writer and analyst. Your task is to transform the provided video transcript into a well-structured, readable, and academically accurate summary document in Markdown format.
        
        ### Preprocessing Rules
        * If there are typos, homophones, or ASR misrecognitions in the transcript, correct or remove them based on context to produce natural language. However, for **uncertain interpretations, mark them with the \[Uncertain] tag**.
        * Represent mathematical formulas or algorithms in LaTeX format whenever possible (`$$...$$`).
        
        **Strictly follow the structure and Markdown specifications below for your entire response:**
        
        ## üìù Summary
        A concise one-paragraph overview of the video‚Äôs topic, purpose, and key findings.
        
        ## üîë Key Concepts and Keywords
        * **Term A:** brief explanation, importance (high/medium/low).
        * **Term B:** ...
        
        ## ‚ú® Key Points (Bulleted List)
        List several key takeaways or findings from the video in concise, easy-to-read bullet points. Each item should be a complete sentence.
        
        ## üìÑ Detailed Analysis
        Logically and structurally connect the main ideas presented in the video, and explain them in a way that even high school students can understand by covering ‚Äúbackground,‚Äù ‚Äúhow,‚Äù ‚Äúwhy,‚Äù and ‚Äúexamples or intuitive explanations.‚Äù Adjust the length according to the complexity of the explanation.
        * Include short pseudocode, schematic explanations, or formulas (LaTeX) where necessary.
        * If the section becomes long, divide it with subheadings (###).
        
        ## üí¨ Notable Quotes
        Extract 2‚Äì3 of the most important or impactful quotes from the transcript that capture central ideas. Format them using Markdown blockquotes:
        > "Impactful Quote 1..."
        > "Impactful Quote 2..."
        
        ## üßê Critical Evaluation
        Point out any gaps, overlooked perspectives, weak arguments, or clear errors in the video‚Äôs discussion. Also, suggest what could have been included to strengthen the explanation.
        
        ## üöÄ Practical Lessons and Conclusion
        Conclude with the key lessons learned. What should the viewer do, remember, or consider after watching this video? This can be expressed in a short paragraph or as a final set of bullet points.
        
        ---
        
        The transcript to summarize is as follows:
        {text}
        """
    
    data = {
        "contents": [
            {
                "parts": [
                    {
                        "text": prompt
                    }
                ]
            }
        ]
    }
    
    try:
        # Prepare the request
        json_data = json.dumps(data).encode('utf-8')
        req = urllib.request.Request(url, data=json_data)
        req.add_header('Content-Type', 'application/json')
        
        print(f"Calling Gemini API for summarization (language: {language})...")
        
        # Make the request
        with urllib.request.urlopen(req) as response:
            result = json.loads(response.read().decode('utf-8'))
            
        # Extract the generated text
        if 'candidates' in result and len(result['candidates']) > 0:
            candidate = result['candidates'][0]
            if 'content' in candidate and 'parts' in candidate['content']:
                summary = candidate['content']['parts'][0]['text']
                print("Successfully generated summary")
                return summary
            else:
                print("Unexpected API response structure")
                return None
        else:
            print("No candidates in API response")
            return None
            
    except urllib.error.HTTPError as e:
        error_body = e.read().decode('utf-8')
        print(f"HTTP Error {e.code}: {error_body}")
        return None
    except Exception as e:
        print(f"Error calling Gemini API: {str(e)}")
        return None


def create_summary_markdown(video_info, summary):
    """Create a markdown file with the Gemini-generated summary."""
    title = video_info.get('title', 'Unknown Title')
    video_id = video_info.get('id', 'Unknown ID')
    duration = video_info.get('duration', 0)
    
    markdown = f"# {title} - Summary\n\n"
    markdown += f"**Video ID:** {video_id}  \n"
    markdown += f"**YouTube URL:** https://www.youtube.com/watch?v={video_id}  \n"
    markdown += f"**Duration:** {format_timestamp(duration)}\n\n"
    markdown += "---\n\n"
    
    if summary:
        markdown += summary
    else:
        markdown += "*Failed to generate summary.*\n"
    
    markdown += "\n\n---\n\n"
    markdown += "*Summary generated using Gemini AI*\n"
    
    return markdown


def main():
    parser = argparse.ArgumentParser(description='Extract YouTube transcript using yt-dlp')
    parser.add_argument('url', help='YouTube URL or video ID')
    parser.add_argument('-o', '--output', help='Output file (default: video_id_transcript.md)')
    parser.add_argument('--no-timestamps', action='store_true', help='Exclude timestamps from output')
    parser.add_argument('--no-summary', action='store_true', help='Skip summary generation')
    parser.add_argument('--summary-lang', choices=['auto', 'en', 'ja'], default='auto', 
                       help='Summary language: auto (same as original), en (English), ja (Japanese)')
    
    args = parser.parse_args()
    
    # Extract video ID for filename if needed
    video_id = extract_video_id(args.url)
    if not video_id:
        print(f"Error: Could not extract a valid YouTube video ID from '{args.url}'")
        sys.exit(1)
    
    # Get video info and transcript
    video_info, transcript_data = get_video_info_and_transcript(video_id)
    
    if not video_info:
        print("Failed to get video information")
        sys.exit(1)
    
    if not transcript_data:
        print("No transcript data available")
        sys.exit(1)
    
    # Download and parse transcript
    transcript = download_and_parse_transcript(transcript_data)
    
    if not transcript:
        print("Failed to parse transcript")
        sys.exit(1)
    
    print(f"Successfully parsed {len(transcript)} transcript entries")
    
    # Convert to markdown
    include_timestamps = not args.no_timestamps
    markdown = transcript_to_markdown(transcript, video_info, include_timestamps)
    
    # Save original transcript to file
    output_file = args.output or f"{video_id}_transcript.md"
    
    try:
        with open(output_file, 'w', encoding='utf-8') as f:
            f.write(markdown)
        print(f"Transcript saved to: {output_file}")
    except Exception as e:
        print(f"Error saving file: {str(e)}")
        print("\n--- Transcript Content ---")
        print(markdown)
        return
    
    # Generate summary if API key is configured and not disabled
    if GEMINI_API_KEY and GEMINI_API_KEY != "YOUR_GEMINI_API_KEY" and not args.no_summary:
        print("\nGenerating summary...")
        
        # Limit text length for API (Gemini has token limits)
        if len(markdown) > MAX_SUMMARY_LENGTH:
            markdown = markdown[:MAX_SUMMARY_LENGTH] + "... [transcript truncated for summarization]"
            print(f"Transcript truncated to {MAX_SUMMARY_LENGTH} characters for summarization")
        
        # Call Gemini API with language preference
        summary = call_gemini_api(markdown, GEMINI_API_KEY, args.summary_lang)

        if summary:
            # Create summary markdown
            summary_markdown = create_summary_markdown(video_info, summary)
            
            # Save summary to file
            summary_file = f"{video_id}_summarized.md"
            
            try:
                with open(summary_file, 'w', encoding='utf-8') as f:
                    f.write(summary_markdown)
                print(f"Summary saved to: {summary_file}")
            except Exception as e:
                print(f"Error saving summary file: {str(e)}")
                print("\n--- Summary Content ---")
                print(summary_markdown)
        else:
            print("Failed to generate summary")
    elif args.no_summary:
        print("Summary generation skipped (--no-summary flag used)")
    elif not GEMINI_API_KEY or GEMINI_API_KEY == "YOUR_GEMINI_API_KEY":
        print("No Gemini API key configured. Set GEMINI_API_KEY in the script to enable summarization.")
    else:
        print("Summarization disabled")


if __name__ == "__main__":
    if len(sys.argv) == 1:
        print("Usage: python yt_dlp_transcript.py <YouTube_URL_or_Video_ID>")
        print("Example: python yt_dlp_transcript.py 'https://www.youtube.com/watch?v=dQw4w9WgXcQ'")
        print("\nOptions:")
        print("  --no-timestamps    Exclude timestamps from output")
        print("  --no-summary       Skip summary generation")
        print("  --summary-lang     Summary language: auto (default), en, ja")
        print("  -o FILE            Output filename")
        print("\nExamples:")
        print("  python yt_dlp_transcript.py 'VIDEO_URL'")
        print("  python yt_dlp_transcript.py 'VIDEO_URL' --summary-lang ja")
        print("  python yt_dlp_transcript.py 'VIDEO_URL' --summary-lang en")
        sys.exit(1)
    
    main()